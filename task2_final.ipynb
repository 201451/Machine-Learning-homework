{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    \n",
    "\n",
    "def dice_coefficient(mask1, mask2):\n",
    "    intersection = np.sum(np.logical_and(mask1, mask2))\n",
    "    union = np.sum(np.logical_or(mask1, mask2))\n",
    "    \n",
    "    dice = (2.0 * intersection) / (union + intersection)\n",
    "    return dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理文件路径\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import os\n",
    "training_train = [1,2,3,4,5,6,7,8,9,10,21,22,23,24,25,26,27,28,29,30,31,32,33,34]\n",
    "training_test =[35,36,37,38,39,40]\n",
    "training=[1,2,3,4,5,6,7,8,9,10,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40]\n",
    "image_dir = 'RawData/Training/imagesTr'\n",
    "label_dir = 'RawData/Training/labelsTr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化和配置一个用于图像分割任务的深度学习模型\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "device =\"cuda\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6532324359954136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15921\\AppData\\Local\\Temp\\ipykernel_16416\\3140221629.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss=torch.tensor((1-dice_tensor)*(1-dice_tensor),requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6605175390205862\n",
      "0.648856640173609\n",
      "0.6711742786764132\n",
      "0.6652599318006805\n",
      "0.6592977586462829\n",
      "0.6706734907585711\n",
      "0.6687158290685811\n",
      "0.6673886078245513\n",
      "0.6557984743762273\n",
      "0.5193166556237327\n",
      "0.5256575644967201\n",
      "0.5443172748669228\n",
      "0.5412868123750355\n",
      "0.5217958726964907\n",
      "0.5307700860317741\n",
      "0.5213421686231395\n",
      "0.5312663021224208\n",
      "0.510967533901885\n",
      "0.5286986194897922\n",
      "0.6344788458758233\n",
      "0.6256560608253608\n",
      "0.6298765060453938\n",
      "0.630665755127036\n",
      "0.6314204463564164\n",
      "0.6215037040702137\n",
      "0.6269229856449327\n",
      "0.6267997781619916\n",
      "0.6353832207573376\n",
      "0.6316990769083605\n",
      "0.6886643906140657\n",
      "0.6939859973618082\n",
      "0.687750718241865\n",
      "0.6872339104058725\n",
      "0.693233868619386\n",
      "0.6741680662844434\n",
      "0.693167086708595\n",
      "0.6864280964707353\n",
      "0.6909404378338018\n",
      "0.6791668268942045\n",
      "0.5589229691596402\n",
      "0.5564485888726638\n",
      "0.5584315848998022\n",
      "0.5474607731143751\n",
      "0.5562945168720554\n",
      "0.5550176198562747\n",
      "0.546262928416384\n",
      "0.5538672244487896\n",
      "0.5536101783028354\n",
      "0.5499158343126873\n",
      "0.559004300569324\n",
      "0.567112972288801\n",
      "0.5561154216491715\n",
      "0.5716140370210687\n",
      "0.5615520639043471\n",
      "0.5668634662040557\n",
      "0.5701973151660917\n",
      "0.5771409128072014\n",
      "0.5718308640344221\n",
      "0.5702184739442477\n",
      "0.4581707603051476\n",
      "0.4492133099616358\n",
      "0.4497562026432637\n",
      "0.4495718855880419\n",
      "0.44760895418796415\n",
      "0.4380937633006643\n",
      "0.4395769424060274\n",
      "0.4502876168556247\n",
      "0.44724623864548446\n",
      "0.45970495248864496\n",
      "0.6450870859459721\n",
      "0.6657045512499545\n",
      "0.6503994897329715\n",
      "0.6518895014006194\n",
      "0.6593068901906969\n",
      "0.6689019948213145\n",
      "0.664088093182438\n",
      "0.6644972025756345\n",
      "0.66685800815379\n",
      "0.6504898456699096\n",
      "0.48201338559960255\n",
      "0.4752615902897592\n",
      "0.47132332160937807\n",
      "0.475629317276275\n",
      "0.47670314975210515\n",
      "0.48295091643554394\n",
      "0.471985364168184\n",
      "0.48184244784399005\n",
      "0.46971958693780735\n",
      "0.47808904450843137\n",
      "0.5786093214939468\n",
      "0.5785331741571534\n",
      "0.5781786994518764\n",
      "0.5792289274312518\n",
      "0.5848518761100429\n",
      "0.5879113928593597\n",
      "0.5818078970321261\n",
      "0.586672508146999\n",
      "0.5831124189771185\n",
      "0.5821915500728717\n",
      "0.5265263414062794\n",
      "0.5197688500269148\n",
      "0.4973821549123798\n",
      "0.5087813446762761\n",
      "0.5308622697127109\n",
      "0.524749142647031\n",
      "0.5213914406253715\n",
      "0.5201502161955728\n",
      "0.5169367110311388\n",
      "0.5084487836837441\n",
      "0.6222933008738256\n",
      "0.6054908139400916\n",
      "0.6202581112668399\n",
      "0.5982618419410671\n",
      "0.6165630955884704\n",
      "0.6017974366383702\n",
      "0.6222521204770348\n",
      "0.5886281309885477\n",
      "0.6275337502429045\n",
      "0.6146031700904258\n",
      "0.5480748790100138\n",
      "0.5489301139193915\n",
      "0.5522840247063017\n",
      "0.5552160179101178\n",
      "0.552911872717774\n",
      "0.5531684892578718\n",
      "0.5494395192430039\n",
      "0.5577817437338496\n",
      "0.5573892040171716\n",
      "0.5460976720497973\n",
      "0.6176934054267963\n",
      "0.6083851109389637\n",
      "0.6092787254196517\n",
      "0.6120588169202167\n",
      "0.6177775390577149\n",
      "0.6034859269586325\n",
      "0.6058049622605607\n",
      "0.585688826874366\n",
      "0.6124151075252603\n",
      "0.6123467318451653\n",
      "0.6313640178590667\n",
      "0.6180281367867966\n",
      "0.6151442698132498\n",
      "0.6090777686585976\n",
      "0.615840010373946\n",
      "0.6268313063742164\n",
      "0.6274993229971844\n",
      "0.6433414723256177\n",
      "0.6216760647971503\n",
      "0.6153904075855846\n",
      "0.48774757117750106\n",
      "0.48380878475511163\n",
      "0.49407162632594037\n",
      "0.4940563388738172\n",
      "0.49387890128790585\n",
      "0.49265304267241394\n",
      "0.48397457900724866\n",
      "0.4941477650313116\n",
      "0.49951238515432467\n",
      "0.49581541864458223\n",
      "0.4859368533713909\n",
      "0.48988276174970025\n",
      "0.4909913189268027\n",
      "0.48516771950602605\n",
      "0.4963507580851524\n",
      "0.4860473213945578\n",
      "0.4813774666985731\n",
      "0.47106157342404525\n",
      "0.4804857669054157\n",
      "0.48604309026291737\n",
      "0.5857614624599213\n",
      "0.5981677466882246\n",
      "0.5795392053470495\n",
      "0.5885962597715887\n",
      "0.5993028488607528\n",
      "0.6102304399815087\n",
      "0.6060841511728225\n",
      "0.6067026339718449\n",
      "0.6026988434883859\n",
      "0.5723821741152313\n",
      "0.6426881603608083\n",
      "0.6491129182158618\n",
      "0.632406250494395\n",
      "0.6485666870230046\n",
      "0.6541062113067624\n",
      "0.6432685663988271\n",
      "0.6451518109647929\n",
      "0.6326056011045705\n",
      "0.6560640142206062\n",
      "0.6436717618728881\n",
      "0.6391449191918749\n",
      "0.6250485355075182\n",
      "0.6268942122841565\n",
      "0.6297702865702673\n",
      "0.6297685893292162\n",
      "0.6439942153717988\n",
      "0.6407116177705168\n",
      "0.6270518960891196\n",
      "0.6398212292464591\n",
      "0.624844048759887\n",
      "0.6290005637261722\n",
      "0.6352643503214741\n",
      "0.635260032848463\n",
      "0.6403075078604951\n",
      "0.6338797418561637\n",
      "0.6379151536437176\n",
      "0.6355959155707106\n",
      "0.6346170728770043\n",
      "0.6379518711311162\n",
      "0.633203588063035\n",
      "0.6041150678419853\n",
      "0.6058387834057604\n",
      "0.590889441001017\n",
      "0.6079586764335085\n",
      "0.5956883900070034\n",
      "0.6014936490605992\n",
      "0.6154088685314177\n",
      "0.5941317635959564\n",
      "0.6232740336790302\n",
      "0.5868243779638818\n",
      "0.5384060985376545\n",
      "0.5286203295044458\n",
      "0.5344279113626729\n",
      "0.5386126310067435\n",
      "0.5206178679893753\n",
      "0.5551551269871894\n",
      "0.5519188592703161\n",
      "0.5394875976285345\n",
      "0.5334604028741018\n",
      "0.5300469875943885\n",
      "0.7229931541061916\n",
      "0.7065416288063376\n",
      "0.6998421736679421\n",
      "0.7375654419026735\n",
      "0.7316561201195128\n",
      "0.7321509204159787\n",
      "0.7011365327088454\n",
      "0.7163695038716246\n",
      "0.7042373730231897\n",
      "0.7301398398160087\n"
     ]
    }
   ],
   "source": [
    "# 设置adam优化器，学习率为1e-5\n",
    "# 每次执行10次迭代\n",
    "# 损失函数采用(1-dice)^2\n",
    "# 使用反向传播来计算梯度\n",
    "for T in training_train:\n",
    "    optimizer=torch.optim.Adam(sam.parameters(),lr=1e-5)\n",
    "    for epoch in range(10):\n",
    "        optimizer.zero_grad()\n",
    "        # 找到图片和标签的路径\n",
    "        image_filename = f\"img{str(T).zfill(4)}.nii.gz\"\n",
    "        image_path = os.path.join(image_dir, image_filename)\n",
    "        file_img = nib.load(image_path)\n",
    "        data_img = file_img.get_fdata()\n",
    "\n",
    "        label_filename = f\"label{str(T).zfill(4)}.nii.gz\"\n",
    "        label_path = os.path.join(label_dir, label_filename)\n",
    "        file_label = nib.load(label_path)\n",
    "        data_label = file_label.get_fdata()\n",
    "\n",
    "        total_img = data_img.shape[2]\n",
    "\n",
    "        unique_gray_val = set()\n",
    "        for picnum in range(total_img):\n",
    "            slice_normalized_label = cv2.normalize(data_label[:,:,picnum], None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "            slice_8bit_label = np.uint8(slice_normalized_label)\n",
    "            non_zero_values = np.unique(slice_8bit_label[slice_8bit_label != 0])\n",
    "            unique_gray_val.update(non_zero_values)\n",
    "                        \n",
    "        # 初始化两个列表\n",
    "        num_grays = len(unique_gray_val)\n",
    "        value_vector = [0] * num_grays\n",
    "        num_vector = [0] * num_grays\n",
    "\n",
    "        for picnum in range(total_img):\n",
    "            slice_normalized_label = cv2.normalize(data_label[:,:,picnum], None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "            slice_8bit_label = np.uint8(slice_normalized_label)\n",
    "            slice_bgr_label = cv2.cvtColor(slice_8bit_label, cv2.COLOR_GRAY2BGR)\n",
    "            # 分解出所有像素点\n",
    "            h, w = slice_8bit_label.shape\n",
    "            nonzero_mask = slice_8bit_label != 0\n",
    "            y_coords, x_coords = np.nonzero(nonzero_mask)\n",
    "            gray_values = slice_8bit_label[nonzero_mask]\n",
    "            pixel_data_label = list(zip(x_coords, y_coords, gray_values))\n",
    "            pixel_data_array_label = np.array(pixel_data_label, dtype=np.int32)\n",
    "\n",
    "            if pixel_data_array_label.shape[0] == 0 :\n",
    "                continue\n",
    "            unique_gray_values = np.unique(pixel_data_array_label[:, 2])\n",
    "\n",
    "            # 将灰度图转换为三通道BGR图像\n",
    "            slice_normalized_img = cv2.normalize(data_img[:,:,picnum], None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "            slice_8bit_img = np.uint8(slice_normalized_img)\n",
    "            image = cv2.cvtColor(slice_8bit_img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            predictor.set_image(image)\n",
    "            # 遍历每个灰度值，对每个器官单独进行取点\n",
    "            for color in unique_gray_values:\n",
    "                indices = np.where(pixel_data_array_label[:, 2] == color)\n",
    "                # 随机选k个点，并获得他们的坐标\n",
    "                k=1\n",
    "                tmp_k=min(k, len(indices[0]))\n",
    "                selected_indices = np.random.choice(len(indices[0]), tmp_k, replace=False)\n",
    "                selected_points_coords = list(zip(pixel_data_array_label[indices, 0][0][selected_indices],\n",
    "                                                    pixel_data_array_label[indices, 1][0][selected_indices]))\n",
    "                input_label = np.ones(tmp_k, dtype=int)\n",
    "                input_point = np.array(selected_points_coords)\n",
    "                input_label = np.array(input_label)\n",
    "                masks, scores, logits = predictor.predict(\n",
    "                    point_coords=input_point,\n",
    "                    point_labels=input_label,\n",
    "                    multimask_output=True,\n",
    "                )\n",
    "\n",
    "                mask = masks[0]\n",
    "                score = scores[0]\n",
    "                new_space = slice_normalized_label\n",
    "                # 将生成的掩码（mask）和地面实况掩码（slice_8bit_label）二值化\n",
    "                slice_8bit_label_now = np.uint8(new_space)\n",
    "                slice_8bit_label_now[slice_8bit_label_now != color] = 0\n",
    "                binary_mask = (mask > 0).astype(np.uint8)\n",
    "                binary_ground_truth = (slice_8bit_label_now > 0).astype(np.uint8)\n",
    "                # 计算Dice系数\n",
    "                dice = dice_coefficient(binary_mask, binary_ground_truth)\n",
    "                for i, tmp in enumerate(unique_gray_val):\n",
    "                    if color == tmp:\n",
    "                        value_vector[i] += dice\n",
    "                        num_vector[i] += 1\n",
    "                        break\n",
    "        \n",
    "        dice = 0\n",
    "        for i in range(0, num_grays):\n",
    "            dice += value_vector[i]/num_vector[i]\n",
    "        dice=dice/num_grays\n",
    "        print(dice)\n",
    "        dice_tensor=torch.tensor(dice)\n",
    "        loss=torch.tensor((1-dice_tensor)*(1-dice_tensor),requires_grad=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "sam.eval()\n",
    "\n",
    "# 保存模型状态字典\n",
    "torch.save(sam.state_dict(), 'module_vit_h.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
